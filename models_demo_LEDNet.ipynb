{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francescobaraldi/opt/anaconda3/envs/cv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models import dataset, training_and_testing\n",
    "from models.LEDNet.models import lednet\n",
    "from metrics_and_losses import metrics\n",
    "from utils import segmentation_labels, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from palette_classification import color_processing\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "n_examples = 5\n",
    "model_name = 'lednet_ccncsa'\n",
    "weights_path = \"models/weights/\"\n",
    "dataset_path = \"headsegmentation_dataset_ccncsa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining transforms\n",
    "tH, tW = 256, 256\n",
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225] # from ImageNet\n",
    "image_transform = T.Compose([T.Resize((tH, tW)), T.Normalize(mean, std)])\n",
    "target_transform = T.Compose([T.Resize((tH, tW))])\n",
    "\n",
    "# fetching dataset\n",
    "n_classes = len(segmentation_labels.labels)\n",
    "img_paths, label_paths = dataset.get_paths(dataset_path + 'training.xml')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(img_paths, label_paths, test_size=0.20, random_state=99, shuffle=True)\n",
    "train_dataset = dataset.MyDataset(X_train, Y_train, image_transform, target_transform)\n",
    "test_dataset = dataset.MyDataset(X_test, Y_test, image_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         MaxPool2d-1          [32, 3, 128, 128]               0\n",
      "            Conv2d-2         [32, 29, 128, 128]             812\n",
      "       BatchNorm2d-3         [32, 32, 128, 128]              64\n",
      "              ReLU-4         [32, 32, 128, 128]               0\n",
      "  DownsamplerBlock-5         [32, 32, 128, 128]               0\n",
      "            Conv2d-6         [32, 16, 128, 128]             784\n",
      "              ReLU-7         [32, 16, 128, 128]               0\n",
      "            Conv2d-8         [32, 16, 128, 128]             784\n",
      "       BatchNorm2d-9         [32, 16, 128, 128]              32\n",
      "             ReLU-10         [32, 16, 128, 128]               0\n",
      "           Conv2d-11         [32, 16, 128, 128]             784\n",
      "             ReLU-12         [32, 16, 128, 128]               0\n",
      "           Conv2d-13         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-14         [32, 16, 128, 128]              32\n",
      "           Conv2d-15         [32, 16, 128, 128]             784\n",
      "             ReLU-16         [32, 16, 128, 128]               0\n",
      "           Conv2d-17         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-18         [32, 16, 128, 128]              32\n",
      "             ReLU-19         [32, 16, 128, 128]               0\n",
      "           Conv2d-20         [32, 16, 128, 128]             784\n",
      "             ReLU-21         [32, 16, 128, 128]               0\n",
      "           Conv2d-22         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-23         [32, 16, 128, 128]              32\n",
      "        Dropout2d-24         [32, 16, 128, 128]               0\n",
      "        Dropout2d-25         [32, 16, 128, 128]               0\n",
      "    SS_nbt_module-26         [32, 32, 128, 128]               0\n",
      "           Conv2d-27         [32, 16, 128, 128]             784\n",
      "             ReLU-28         [32, 16, 128, 128]               0\n",
      "           Conv2d-29         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-30         [32, 16, 128, 128]              32\n",
      "             ReLU-31         [32, 16, 128, 128]               0\n",
      "           Conv2d-32         [32, 16, 128, 128]             784\n",
      "             ReLU-33         [32, 16, 128, 128]               0\n",
      "           Conv2d-34         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-35         [32, 16, 128, 128]              32\n",
      "           Conv2d-36         [32, 16, 128, 128]             784\n",
      "             ReLU-37         [32, 16, 128, 128]               0\n",
      "           Conv2d-38         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-39         [32, 16, 128, 128]              32\n",
      "             ReLU-40         [32, 16, 128, 128]               0\n",
      "           Conv2d-41         [32, 16, 128, 128]             784\n",
      "             ReLU-42         [32, 16, 128, 128]               0\n",
      "           Conv2d-43         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-44         [32, 16, 128, 128]              32\n",
      "        Dropout2d-45         [32, 16, 128, 128]               0\n",
      "        Dropout2d-46         [32, 16, 128, 128]               0\n",
      "    SS_nbt_module-47         [32, 32, 128, 128]               0\n",
      "           Conv2d-48         [32, 16, 128, 128]             784\n",
      "             ReLU-49         [32, 16, 128, 128]               0\n",
      "           Conv2d-50         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-51         [32, 16, 128, 128]              32\n",
      "             ReLU-52         [32, 16, 128, 128]               0\n",
      "           Conv2d-53         [32, 16, 128, 128]             784\n",
      "             ReLU-54         [32, 16, 128, 128]               0\n",
      "           Conv2d-55         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-56         [32, 16, 128, 128]              32\n",
      "           Conv2d-57         [32, 16, 128, 128]             784\n",
      "             ReLU-58         [32, 16, 128, 128]               0\n",
      "           Conv2d-59         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-60         [32, 16, 128, 128]              32\n",
      "             ReLU-61         [32, 16, 128, 128]               0\n",
      "           Conv2d-62         [32, 16, 128, 128]             784\n",
      "             ReLU-63         [32, 16, 128, 128]               0\n",
      "           Conv2d-64         [32, 16, 128, 128]             784\n",
      "      BatchNorm2d-65         [32, 16, 128, 128]              32\n",
      "        Dropout2d-66         [32, 16, 128, 128]               0\n",
      "        Dropout2d-67         [32, 16, 128, 128]               0\n",
      "    SS_nbt_module-68         [32, 32, 128, 128]               0\n",
      "        MaxPool2d-69           [32, 32, 64, 64]               0\n",
      "           Conv2d-70           [32, 32, 64, 64]           9,248\n",
      "      BatchNorm2d-71           [32, 64, 64, 64]             128\n",
      "             ReLU-72           [32, 64, 64, 64]               0\n",
      " DownsamplerBlock-73           [32, 64, 64, 64]               0\n",
      "           Conv2d-74           [32, 32, 64, 64]           3,104\n",
      "             ReLU-75           [32, 32, 64, 64]               0\n",
      "           Conv2d-76           [32, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-77           [32, 32, 64, 64]              64\n",
      "             ReLU-78           [32, 32, 64, 64]               0\n",
      "           Conv2d-79           [32, 32, 64, 64]           3,104\n",
      "             ReLU-80           [32, 32, 64, 64]               0\n",
      "           Conv2d-81           [32, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-82           [32, 32, 64, 64]              64\n",
      "           Conv2d-83           [32, 32, 64, 64]           3,104\n",
      "             ReLU-84           [32, 32, 64, 64]               0\n",
      "           Conv2d-85           [32, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-86           [32, 32, 64, 64]              64\n",
      "             ReLU-87           [32, 32, 64, 64]               0\n",
      "           Conv2d-88           [32, 32, 64, 64]           3,104\n",
      "             ReLU-89           [32, 32, 64, 64]               0\n",
      "           Conv2d-90           [32, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-91           [32, 32, 64, 64]              64\n",
      "        Dropout2d-92           [32, 32, 64, 64]               0\n",
      "        Dropout2d-93           [32, 32, 64, 64]               0\n",
      "    SS_nbt_module-94           [32, 64, 64, 64]               0\n",
      "           Conv2d-95           [32, 32, 64, 64]           3,104\n",
      "             ReLU-96           [32, 32, 64, 64]               0\n",
      "           Conv2d-97           [32, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-98           [32, 32, 64, 64]              64\n",
      "             ReLU-99           [32, 32, 64, 64]               0\n",
      "          Conv2d-100           [32, 32, 64, 64]           3,104\n",
      "            ReLU-101           [32, 32, 64, 64]               0\n",
      "          Conv2d-102           [32, 32, 64, 64]           3,104\n",
      "     BatchNorm2d-103           [32, 32, 64, 64]              64\n",
      "          Conv2d-104           [32, 32, 64, 64]           3,104\n",
      "            ReLU-105           [32, 32, 64, 64]               0\n",
      "          Conv2d-106           [32, 32, 64, 64]           3,104\n",
      "     BatchNorm2d-107           [32, 32, 64, 64]              64\n",
      "            ReLU-108           [32, 32, 64, 64]               0\n",
      "          Conv2d-109           [32, 32, 64, 64]           3,104\n",
      "            ReLU-110           [32, 32, 64, 64]               0\n",
      "          Conv2d-111           [32, 32, 64, 64]           3,104\n",
      "     BatchNorm2d-112           [32, 32, 64, 64]              64\n",
      "       Dropout2d-113           [32, 32, 64, 64]               0\n",
      "       Dropout2d-114           [32, 32, 64, 64]               0\n",
      "   SS_nbt_module-115           [32, 64, 64, 64]               0\n",
      "       MaxPool2d-116           [32, 64, 32, 32]               0\n",
      "          Conv2d-117           [32, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-118          [32, 128, 32, 32]             256\n",
      "            ReLU-119          [32, 128, 32, 32]               0\n",
      "DownsamplerBlock-120          [32, 128, 32, 32]               0\n",
      "          Conv2d-121           [32, 64, 32, 32]          12,352\n",
      "            ReLU-122           [32, 64, 32, 32]               0\n",
      "          Conv2d-123           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-124           [32, 64, 32, 32]             128\n",
      "            ReLU-125           [32, 64, 32, 32]               0\n",
      "          Conv2d-126           [32, 64, 32, 32]          12,352\n",
      "            ReLU-127           [32, 64, 32, 32]               0\n",
      "          Conv2d-128           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-129           [32, 64, 32, 32]             128\n",
      "          Conv2d-130           [32, 64, 32, 32]          12,352\n",
      "            ReLU-131           [32, 64, 32, 32]               0\n",
      "          Conv2d-132           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-133           [32, 64, 32, 32]             128\n",
      "            ReLU-134           [32, 64, 32, 32]               0\n",
      "          Conv2d-135           [32, 64, 32, 32]          12,352\n",
      "            ReLU-136           [32, 64, 32, 32]               0\n",
      "          Conv2d-137           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-138           [32, 64, 32, 32]             128\n",
      "       Dropout2d-139           [32, 64, 32, 32]               0\n",
      "       Dropout2d-140           [32, 64, 32, 32]               0\n",
      "   SS_nbt_module-141          [32, 128, 32, 32]               0\n",
      "          Conv2d-142           [32, 64, 32, 32]          12,352\n",
      "            ReLU-143           [32, 64, 32, 32]               0\n",
      "          Conv2d-144           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-145           [32, 64, 32, 32]             128\n",
      "            ReLU-146           [32, 64, 32, 32]               0\n",
      "          Conv2d-147           [32, 64, 32, 32]          12,352\n",
      "            ReLU-148           [32, 64, 32, 32]               0\n",
      "          Conv2d-149           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-150           [32, 64, 32, 32]             128\n",
      "          Conv2d-151           [32, 64, 32, 32]          12,352\n",
      "            ReLU-152           [32, 64, 32, 32]               0\n",
      "          Conv2d-153           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-154           [32, 64, 32, 32]             128\n",
      "            ReLU-155           [32, 64, 32, 32]               0\n",
      "          Conv2d-156           [32, 64, 32, 32]          12,352\n",
      "            ReLU-157           [32, 64, 32, 32]               0\n",
      "          Conv2d-158           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-159           [32, 64, 32, 32]             128\n",
      "       Dropout2d-160           [32, 64, 32, 32]               0\n",
      "       Dropout2d-161           [32, 64, 32, 32]               0\n",
      "   SS_nbt_module-162          [32, 128, 32, 32]               0\n",
      "          Conv2d-163           [32, 64, 32, 32]          12,352\n",
      "            ReLU-164           [32, 64, 32, 32]               0\n",
      "          Conv2d-165           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-166           [32, 64, 32, 32]             128\n",
      "            ReLU-167           [32, 64, 32, 32]               0\n",
      "          Conv2d-168           [32, 64, 32, 32]          12,352\n",
      "            ReLU-169           [32, 64, 32, 32]               0\n",
      "          Conv2d-170           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-171           [32, 64, 32, 32]             128\n",
      "          Conv2d-172           [32, 64, 32, 32]          12,352\n",
      "            ReLU-173           [32, 64, 32, 32]               0\n",
      "          Conv2d-174           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-175           [32, 64, 32, 32]             128\n",
      "            ReLU-176           [32, 64, 32, 32]               0\n",
      "          Conv2d-177           [32, 64, 32, 32]          12,352\n",
      "            ReLU-178           [32, 64, 32, 32]               0\n",
      "          Conv2d-179           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-180           [32, 64, 32, 32]             128\n",
      "       Dropout2d-181           [32, 64, 32, 32]               0\n",
      "       Dropout2d-182           [32, 64, 32, 32]               0\n",
      "   SS_nbt_module-183          [32, 128, 32, 32]               0\n",
      "          Conv2d-184           [32, 64, 32, 32]          12,352\n",
      "            ReLU-185           [32, 64, 32, 32]               0\n",
      "          Conv2d-186           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-187           [32, 64, 32, 32]             128\n",
      "            ReLU-188           [32, 64, 32, 32]               0\n",
      "          Conv2d-189           [32, 64, 32, 32]          12,352\n",
      "            ReLU-190           [32, 64, 32, 32]               0\n",
      "          Conv2d-191           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-192           [32, 64, 32, 32]             128\n",
      "          Conv2d-193           [32, 64, 32, 32]          12,352\n",
      "            ReLU-194           [32, 64, 32, 32]               0\n",
      "          Conv2d-195           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-196           [32, 64, 32, 32]             128\n",
      "            ReLU-197           [32, 64, 32, 32]               0\n",
      "          Conv2d-198           [32, 64, 32, 32]          12,352\n",
      "            ReLU-199           [32, 64, 32, 32]               0\n",
      "          Conv2d-200           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-201           [32, 64, 32, 32]             128\n",
      "       Dropout2d-202           [32, 64, 32, 32]               0\n",
      "       Dropout2d-203           [32, 64, 32, 32]               0\n",
      "   SS_nbt_module-204          [32, 128, 32, 32]               0\n",
      "          Conv2d-205           [32, 64, 32, 32]          12,352\n",
      "            ReLU-206           [32, 64, 32, 32]               0\n",
      "          Conv2d-207           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-208           [32, 64, 32, 32]             128\n",
      "            ReLU-209           [32, 64, 32, 32]               0\n",
      "          Conv2d-210           [32, 64, 32, 32]          12,352\n",
      "            ReLU-211           [32, 64, 32, 32]               0\n",
      "          Conv2d-212           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-213           [32, 64, 32, 32]             128\n",
      "          Conv2d-214           [32, 64, 32, 32]          12,352\n",
      "            ReLU-215           [32, 64, 32, 32]               0\n",
      "          Conv2d-216           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-217           [32, 64, 32, 32]             128\n",
      "            ReLU-218           [32, 64, 32, 32]               0\n",
      "          Conv2d-219           [32, 64, 32, 32]          12,352\n",
      "            ReLU-220           [32, 64, 32, 32]               0\n",
      "          Conv2d-221           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-222           [32, 64, 32, 32]             128\n",
      "       Dropout2d-223           [32, 64, 32, 32]               0\n",
      "       Dropout2d-224           [32, 64, 32, 32]               0\n",
      "   SS_nbt_module-225          [32, 128, 32, 32]               0\n",
      "          Conv2d-226           [32, 64, 32, 32]          12,352\n",
      "            ReLU-227           [32, 64, 32, 32]               0\n",
      "          Conv2d-228           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-229           [32, 64, 32, 32]             128\n",
      "            ReLU-230           [32, 64, 32, 32]               0\n",
      "          Conv2d-231           [32, 64, 32, 32]          12,352\n",
      "            ReLU-232           [32, 64, 32, 32]               0\n",
      "          Conv2d-233           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-234           [32, 64, 32, 32]             128\n",
      "          Conv2d-235           [32, 64, 32, 32]          12,352\n",
      "            ReLU-236           [32, 64, 32, 32]               0\n",
      "          Conv2d-237           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-238           [32, 64, 32, 32]             128\n",
      "            ReLU-239           [32, 64, 32, 32]               0\n",
      "          Conv2d-240           [32, 64, 32, 32]          12,352\n",
      "            ReLU-241           [32, 64, 32, 32]               0\n",
      "          Conv2d-242           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-243           [32, 64, 32, 32]             128\n",
      "       Dropout2d-244           [32, 64, 32, 32]               0\n",
      "       Dropout2d-245           [32, 64, 32, 32]               0\n",
      "   SS_nbt_module-246          [32, 128, 32, 32]               0\n",
      "          Conv2d-247           [32, 64, 32, 32]          12,352\n",
      "            ReLU-248           [32, 64, 32, 32]               0\n",
      "          Conv2d-249           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-250           [32, 64, 32, 32]             128\n",
      "            ReLU-251           [32, 64, 32, 32]               0\n",
      "          Conv2d-252           [32, 64, 32, 32]          12,352\n",
      "            ReLU-253           [32, 64, 32, 32]               0\n",
      "          Conv2d-254           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-255           [32, 64, 32, 32]             128\n",
      "          Conv2d-256           [32, 64, 32, 32]          12,352\n",
      "            ReLU-257           [32, 64, 32, 32]               0\n",
      "          Conv2d-258           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-259           [32, 64, 32, 32]             128\n",
      "            ReLU-260           [32, 64, 32, 32]               0\n",
      "          Conv2d-261           [32, 64, 32, 32]          12,352\n",
      "            ReLU-262           [32, 64, 32, 32]               0\n",
      "          Conv2d-263           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-264           [32, 64, 32, 32]             128\n",
      "       Dropout2d-265           [32, 64, 32, 32]               0\n",
      "       Dropout2d-266           [32, 64, 32, 32]               0\n",
      "   SS_nbt_module-267          [32, 128, 32, 32]               0\n",
      "          Conv2d-268           [32, 64, 32, 32]          12,352\n",
      "            ReLU-269           [32, 64, 32, 32]               0\n",
      "          Conv2d-270           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-271           [32, 64, 32, 32]             128\n",
      "            ReLU-272           [32, 64, 32, 32]               0\n",
      "          Conv2d-273           [32, 64, 32, 32]          12,352\n",
      "            ReLU-274           [32, 64, 32, 32]               0\n",
      "          Conv2d-275           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-276           [32, 64, 32, 32]             128\n",
      "          Conv2d-277           [32, 64, 32, 32]          12,352\n",
      "            ReLU-278           [32, 64, 32, 32]               0\n",
      "          Conv2d-279           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-280           [32, 64, 32, 32]             128\n",
      "            ReLU-281           [32, 64, 32, 32]               0\n",
      "          Conv2d-282           [32, 64, 32, 32]          12,352\n",
      "            ReLU-283           [32, 64, 32, 32]               0\n",
      "          Conv2d-284           [32, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-285           [32, 64, 32, 32]             128\n",
      "       Dropout2d-286           [32, 64, 32, 32]               0\n",
      "       Dropout2d-287           [32, 64, 32, 32]               0\n",
      "   SS_nbt_module-288          [32, 128, 32, 32]               0\n",
      "         Encoder-289          [32, 128, 32, 32]               0\n",
      "AdaptiveAvgPool2d-290            [32, 128, 1, 1]               0\n",
      "          Conv2d-291             [32, 11, 1, 1]           1,419\n",
      "     BatchNorm2d-292             [32, 11, 1, 1]              22\n",
      "            ReLU-293             [32, 11, 1, 1]               0\n",
      "    Conv2dBnRelu-294             [32, 11, 1, 1]               0\n",
      "          Conv2d-295           [32, 11, 32, 32]           1,419\n",
      "     BatchNorm2d-296           [32, 11, 32, 32]              22\n",
      "            ReLU-297           [32, 11, 32, 32]               0\n",
      "    Conv2dBnRelu-298           [32, 11, 32, 32]               0\n",
      "          Conv2d-299            [32, 1, 16, 16]           6,273\n",
      "     BatchNorm2d-300            [32, 1, 16, 16]               2\n",
      "            ReLU-301            [32, 1, 16, 16]               0\n",
      "    Conv2dBnRelu-302            [32, 1, 16, 16]               0\n",
      "          Conv2d-303              [32, 1, 8, 8]              26\n",
      "     BatchNorm2d-304              [32, 1, 8, 8]               2\n",
      "            ReLU-305              [32, 1, 8, 8]               0\n",
      "    Conv2dBnRelu-306              [32, 1, 8, 8]               0\n",
      "          Conv2d-307              [32, 1, 4, 4]              10\n",
      "     BatchNorm2d-308              [32, 1, 4, 4]               2\n",
      "            ReLU-309              [32, 1, 4, 4]               0\n",
      "    Conv2dBnRelu-310              [32, 1, 4, 4]               0\n",
      "          Conv2d-311              [32, 1, 4, 4]              10\n",
      "     BatchNorm2d-312              [32, 1, 4, 4]               2\n",
      "            ReLU-313              [32, 1, 4, 4]               0\n",
      "    Conv2dBnRelu-314              [32, 1, 4, 4]               0\n",
      "          Conv2d-315              [32, 1, 8, 8]              26\n",
      "     BatchNorm2d-316              [32, 1, 8, 8]               2\n",
      "            ReLU-317              [32, 1, 8, 8]               0\n",
      "    Conv2dBnRelu-318              [32, 1, 8, 8]               0\n",
      "          Conv2d-319            [32, 1, 16, 16]              50\n",
      "     BatchNorm2d-320            [32, 1, 16, 16]               2\n",
      "            ReLU-321            [32, 1, 16, 16]               0\n",
      "    Conv2dBnRelu-322            [32, 1, 16, 16]               0\n",
      "      APN_Module-323           [32, 11, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 920,725\n",
      "Trainable params: 920,725\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 24.00\n",
      "Forward/backward pass size (MB): 9390.45\n",
      "Params size (MB): 3.51\n",
      "Estimated Total Size (MB): 9417.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# training hyperparameters\n",
    "device = 'cpu'\n",
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "\n",
    "# model, loss, score function\n",
    "model = lednet.LEDNet(num_classes=n_classes, output_size=(tH, tW))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "score_fn = metrics.batch_mIoU\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# printing model summary\n",
    "torchsummary.summary(model=model, input_size=(3, tH, tW), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu.\n",
      "--- Epoch 1/50 ---\n",
      "average_train_loss: 1.2366667499487427, average_train_score: 0.3204895555973053\n",
      "average_val_loss: 0.8590723723173141, average_val_score: 0.3594164550304413\n",
      "--- Epoch 2/50 ---\n",
      "average_train_loss: 0.6789413786482537, average_train_score: 0.37297847867012024\n",
      "average_val_loss: 0.5809650868177414, average_val_score: 0.3895222842693329\n",
      "--- Epoch 3/50 ---\n",
      "average_train_loss: 0.5792185948497948, average_train_score: 0.38377314805984497\n",
      "average_val_loss: 0.6388318724930286, average_val_score: 0.3734949827194214\n",
      "--- Epoch 4/50 ---\n",
      "average_train_loss: 0.5418638648657963, average_train_score: 0.38839834928512573\n",
      "average_val_loss: 0.6193780042231083, average_val_score: 0.3801735043525696\n",
      "--- Epoch 5/50 ---\n",
      "average_train_loss: 0.49772488968125705, average_train_score: 0.39778605103492737\n",
      "average_val_loss: 0.4532705210149288, average_val_score: 0.4076268970966339\n",
      "--- Epoch 6/50 ---\n",
      "average_train_loss: 0.4754013175936951, average_train_score: 0.4041346311569214\n",
      "average_val_loss: 0.4236858934164047, average_val_score: 0.41964614391326904\n",
      "--- Epoch 7/50 ---\n",
      "average_train_loss: 0.4325768656429203, average_train_score: 0.42179369926452637\n",
      "average_val_loss: 0.3906060643494129, average_val_score: 0.4274049699306488\n",
      "--- Epoch 8/50 ---\n",
      "average_train_loss: 0.41905185134931544, average_train_score: 0.43108469247817993\n",
      "average_val_loss: 0.38793302327394485, average_val_score: 0.43439602851867676\n",
      "--- Epoch 9/50 ---\n",
      "average_train_loss: 0.38736416690651027, average_train_score: 0.44459420442581177\n",
      "average_val_loss: 0.37290942296385765, average_val_score: 0.4526941478252411\n",
      "--- Epoch 10/50 ---\n",
      "average_train_loss: 0.3701947423918494, average_train_score: 0.4570697546005249\n",
      "average_val_loss: 0.3927735202014446, average_val_score: 0.4446766674518585\n",
      "--- Epoch 11/50 ---\n",
      "average_train_loss: 0.35073734888400154, average_train_score: 0.4656689465045929\n",
      "average_val_loss: 0.3195247035473585, average_val_score: 0.4824638068675995\n",
      "--- Epoch 12/50 ---\n",
      "average_train_loss: 0.312453353542021, average_train_score: 0.4847247302532196\n",
      "average_val_loss: 0.3057277547195554, average_val_score: 0.473967969417572\n",
      "--- Epoch 13/50 ---\n",
      "average_train_loss: 0.29490075029175855, average_train_score: 0.4975423216819763\n",
      "average_val_loss: 0.4827824719250202, average_val_score: 0.4517183303833008\n",
      "--- Epoch 14/50 ---\n",
      "average_train_loss: 0.2824619224016694, average_train_score: 0.5066437125205994\n",
      "average_val_loss: 0.32826605904847383, average_val_score: 0.49871736764907837\n",
      "--- Epoch 15/50 ---\n",
      "average_train_loss: 0.2708153947331439, average_train_score: 0.5138280987739563\n",
      "average_val_loss: 0.2749926745891571, average_val_score: 0.5117466449737549\n",
      "--- Epoch 16/50 ---\n",
      "average_train_loss: 0.25855404018670664, average_train_score: 0.5243948101997375\n",
      "average_val_loss: 0.2480241833254695, average_val_score: 0.5264261960983276\n",
      "--- Epoch 17/50 ---\n",
      "average_train_loss: 0.23912142063009328, average_train_score: 0.537467896938324\n",
      "average_val_loss: 0.22863163240253925, average_val_score: 0.558591365814209\n",
      "--- Epoch 18/50 ---\n",
      "average_train_loss: 0.22506737400745525, average_train_score: 0.5468264818191528\n",
      "average_val_loss: 0.22471719235181808, average_val_score: 0.5523284673690796\n",
      "--- Epoch 19/50 ---\n",
      "average_train_loss: 0.21620878200421387, average_train_score: 0.5525127053260803\n",
      "average_val_loss: 0.209496078081429, average_val_score: 0.5698164105415344\n",
      "--- Epoch 20/50 ---\n",
      "average_train_loss: 0.20600308803306228, average_train_score: 0.5612143278121948\n",
      "average_val_loss: 0.2081125881522894, average_val_score: 0.5666113495826721\n",
      "--- Epoch 21/50 ---\n",
      "average_train_loss: 0.1976398853049881, average_train_score: 0.5690990090370178\n",
      "average_val_loss: 0.21833979338407516, average_val_score: 0.5736750960350037\n",
      "--- Epoch 22/50 ---\n",
      "average_train_loss: 0.19674635584326997, average_train_score: 0.5697410702705383\n",
      "average_val_loss: 0.19966783560812473, average_val_score: 0.5683377981185913\n",
      "--- Epoch 23/50 ---\n",
      "average_train_loss: 0.1840518810625734, average_train_score: 0.5789896845817566\n",
      "average_val_loss: 0.17900494951754808, average_val_score: 0.5954668521881104\n",
      "--- Epoch 24/50 ---\n",
      "average_train_loss: 0.18004053488545035, average_train_score: 0.5837011933326721\n",
      "average_val_loss: 0.18796764500439167, average_val_score: 0.5831566452980042\n",
      "--- Epoch 25/50 ---\n",
      "average_train_loss: 0.17647288842447872, average_train_score: 0.5869041681289673\n",
      "average_val_loss: 0.19924263190478086, average_val_score: 0.58875572681427\n",
      "--- Epoch 26/50 ---\n",
      "average_train_loss: 0.1809092857714357, average_train_score: 0.5853592753410339\n",
      "average_val_loss: 0.1698313858360052, average_val_score: 0.6084873676300049\n",
      "--- Epoch 27/50 ---\n",
      "average_train_loss: 0.16801628316270895, average_train_score: 0.5923148989677429\n",
      "average_val_loss: 0.17614691145718098, average_val_score: 0.594196081161499\n",
      "--- Epoch 28/50 ---\n",
      "average_train_loss: 0.1685225310168047, average_train_score: 0.5952969193458557\n",
      "average_val_loss: 0.16564263962209225, average_val_score: 0.6042787432670593\n",
      "--- Epoch 29/50 ---\n",
      "average_train_loss: 0.1598970222062078, average_train_score: 0.6016513109207153\n",
      "average_val_loss: 0.15683443564921618, average_val_score: 0.6135965585708618\n",
      "--- Epoch 30/50 ---\n",
      "average_train_loss: 0.15392734290196977, average_train_score: 0.6061902642250061\n",
      "average_val_loss: 0.16388974897563457, average_val_score: 0.6152776479721069\n",
      "--- Epoch 31/50 ---\n",
      "average_train_loss: 0.1451150274824822, average_train_score: 0.6126206517219543\n",
      "average_val_loss: 0.15775666199624538, average_val_score: 0.6213951110839844\n",
      "--- Epoch 32/50 ---\n",
      "average_train_loss: 0.14843222361871566, average_train_score: 0.6083078980445862\n",
      "average_val_loss: 0.16209934279322624, average_val_score: 0.60968416929245\n",
      "--- Epoch 33/50 ---\n",
      "average_train_loss: 0.14703957239786783, average_train_score: 0.611985981464386\n",
      "average_val_loss: 0.15821944642812014, average_val_score: 0.615384578704834\n",
      "--- Epoch 34/50 ---\n",
      "average_train_loss: 0.14391138558757716, average_train_score: 0.6154187321662903\n",
      "average_val_loss: 0.14855858078226447, average_val_score: 0.6280794143676758\n",
      "--- Epoch 35/50 ---\n",
      "average_train_loss: 0.13404800032062092, average_train_score: 0.6239326596260071\n",
      "average_val_loss: 0.15468896087259054, average_val_score: 0.6177530884742737\n",
      "--- Epoch 36/50 ---\n",
      "average_train_loss: 0.13221443333159918, average_train_score: 0.6250990033149719\n",
      "average_val_loss: 0.1421177233569324, average_val_score: 0.6338167190551758\n",
      "--- Epoch 37/50 ---\n",
      "average_train_loss: 0.1332481804079023, average_train_score: 0.6226041913032532\n",
      "average_val_loss: 0.16316034412011504, average_val_score: 0.6196489334106445\n",
      "--- Epoch 38/50 ---\n",
      "average_train_loss: 0.13449940890416331, average_train_score: 0.625222384929657\n",
      "average_val_loss: 0.15250433003529906, average_val_score: 0.621084451675415\n",
      "--- Epoch 39/50 ---\n",
      "average_train_loss: 0.1249483246570346, average_train_score: 0.6310433745384216\n",
      "average_val_loss: 0.14479346945881844, average_val_score: 0.6378212571144104\n",
      "--- Epoch 40/50 ---\n",
      "average_train_loss: 0.12398030900064556, average_train_score: 0.6310197114944458\n",
      "average_val_loss: 0.192869259044528, average_val_score: 0.609027624130249\n",
      "--- Epoch 41/50 ---\n",
      "average_train_loss: 0.12405474278433569, average_train_score: 0.6301243305206299\n",
      "average_val_loss: 0.15171766327694058, average_val_score: 0.6380369067192078\n",
      "--- Epoch 42/50 ---\n",
      "average_train_loss: 0.12036623600228079, average_train_score: 0.6349527835845947\n",
      "average_val_loss: 0.15170768834650517, average_val_score: 0.6442335247993469\n",
      "--- Epoch 43/50 ---\n",
      "average_train_loss: 0.1180384951247566, average_train_score: 0.6366532444953918\n",
      "average_val_loss: 0.14224455878138542, average_val_score: 0.6512492299079895\n",
      "--- Epoch 44/50 ---\n",
      "average_train_loss: 0.1083552139415138, average_train_score: 0.644170343875885\n",
      "average_val_loss: 0.13842935394495726, average_val_score: 0.6457916498184204\n",
      "--- Epoch 45/50 ---\n",
      "average_train_loss: 0.1149254828348927, average_train_score: 0.6391855478286743\n",
      "average_val_loss: 0.14026073459535837, average_val_score: 0.6487350463867188\n",
      "--- Epoch 46/50 ---\n",
      "average_train_loss: 0.11026157824129894, average_train_score: 0.6455196738243103\n",
      "average_val_loss: 0.17376570729538798, average_val_score: 0.6193525195121765\n",
      "--- Epoch 47/50 ---\n",
      "average_train_loss: 0.11283539783680575, average_train_score: 0.6413769125938416\n",
      "average_val_loss: 0.14291744492948055, average_val_score: 0.6471619606018066\n",
      "--- Epoch 48/50 ---\n",
      "average_train_loss: 0.10736579105429266, average_train_score: 0.6473827362060547\n",
      "average_val_loss: 0.1376840090379119, average_val_score: 0.6485006213188171\n",
      "--- Epoch 49/50 ---\n",
      "average_train_loss: 0.10167965044577916, average_train_score: 0.6504037380218506\n",
      "average_val_loss: 0.14175754645839334, average_val_score: 0.646801233291626\n",
      "--- Epoch 50/50 ---\n",
      "average_train_loss: 0.09923084414210813, average_train_score: 0.6540257334709167\n",
      "average_val_loss: 0.1317742341198027, average_val_score: 0.6512649059295654\n",
      "\n",
      "Training completed in around 462 minutes.\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "results = training_and_testing.train_model(\n",
    "    device, model, test_dataset, batch_size, n_epochs, score_fn, loss_fn, optimizer, lr_scheduler=None, evaluate=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting training results\n",
    "training_and_testing.plot_training_results(results, plotsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting model, optimizer, learning rate scheduler\n",
    "final_model = lednet.LEDNet(num_classes=n_classes)\n",
    "final_optimizer = torch.optim.Adam(final_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# re-training model on entire training set and saving its weights\n",
    "final_n_epochs = 25\n",
    "training_and_testing.train_model(\n",
    "    device, final_model, train_dataset, batch_size, final_n_epochs, score_fn, loss_fn, final_optimizer, verbose=True)\n",
    "torch.save(final_model.state_dict(), weights_path + model_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained final model\n",
    "try:\n",
    "    final_model\n",
    "except:\n",
    "    final_model = lednet.LEDNet(num_classes=n_classes)\n",
    "    final_model.load_state_dict(torch.load(weights_path + model_name + '.pth'))\n",
    "\n",
    "# testing model on test dataset\n",
    "test_score_fn = metrics.batch_IoU\n",
    "label_names = list(segmentation_labels.labels.keys())\n",
    "batch_IoU = training_and_testing.test_model(device, final_model, test_dataset, batch_size, test_score_fn)\n",
    "batch_IoU_with_labels = { label: score for label, score in list(zip(label_names, batch_IoU.tolist())) }\n",
    "batch_mIoU = batch_IoU.mean().item()\n",
    "for label in batch_IoU_with_labels:\n",
    "    print(f'batch_IoU_{label}: {batch_IoU_with_labels[label]}')\n",
    "print(f'batch_mIoU={batch_mIoU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting some random examples from test dataset\n",
    "random_images = torch.zeros((n_examples, 3, tH, tW))\n",
    "random_targets = torch.zeros((n_examples, n_classes, tH, tW))\n",
    "for i in range(n_examples):\n",
    "    random_idx = torch.randint(high=len(test_dataset), size=(1,))\n",
    "    random_image, random_target = test_dataset[random_idx]\n",
    "    random_images[i] = random_image\n",
    "    random_targets[i] = random_target\n",
    "with torch.no_grad():\n",
    "    final_model.eval()\n",
    "    random_output = final_model(random_images)[0]\n",
    "channels_max, _ = torch.max(random_output, axis=1)\n",
    "random_predictions = (random_output == channels_max.unsqueeze(axis=1))\n",
    "for i in range(n_examples):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Ground Truth')\n",
    "    plt.imshow(utils.from_DHW_to_HWD(color_processing.colorize_segmentation_masks(random_targets[i], segmentation_labels.labels)))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Prediction')\n",
    "    plt.imshow(utils.from_DHW_to_HWD(color_processing.colorize_segmentation_masks(random_predictions[i], segmentation_labels.labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7035b1fba47350ac926f595c0cf89eb9aa595e837aeef931238e88411bd168d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
