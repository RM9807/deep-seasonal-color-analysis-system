{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models import dataset, training_and_testing\n",
    "from models.LEDNet.models import lednet\n",
    "from metrics_and_losses import metrics\n",
    "from utils import segmentation_labels, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from palette_classification import color_processing\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "n_examples = 5\n",
    "model_name = 'lednet_ccncsa'\n",
    "weights_path = \"models/weights/\"\n",
    "dataset_path = \"headsegmentation_dataset_ccncsa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining transforms\n",
    "tH, tW = 256, 256\n",
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225] # from ImageNet\n",
    "image_transform = T.Compose([T.Resize((tH, tW)), T.Normalize(mean, std)])\n",
    "target_transform = T.Compose([T.Resize((tH, tW))])\n",
    "\n",
    "# fetching dataset\n",
    "n_classes = len(segmentation_labels.labels)\n",
    "img_paths, label_paths = dataset.get_paths(dataset_path + 'training.xml')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(img_paths, label_paths, test_size=0.20, random_state=99, shuffle=True)\n",
    "train_dataset = dataset.MyDataset(X_train, Y_train, image_transform, target_transform)\n",
    "test_dataset = dataset.MyDataset(X_test, Y_test, image_transform, target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         MaxPool2d-1          [64, 3, 128, 128]               0\n",
      "            Conv2d-2         [64, 29, 128, 128]             812\n",
      "       BatchNorm2d-3         [64, 32, 128, 128]              64\n",
      "              ReLU-4         [64, 32, 128, 128]               0\n",
      "  DownsamplerBlock-5         [64, 32, 128, 128]               0\n",
      "            Conv2d-6         [64, 16, 128, 128]             784\n",
      "              ReLU-7         [64, 16, 128, 128]               0\n",
      "            Conv2d-8         [64, 16, 128, 128]             784\n",
      "       BatchNorm2d-9         [64, 16, 128, 128]              32\n",
      "             ReLU-10         [64, 16, 128, 128]               0\n",
      "           Conv2d-11         [64, 16, 128, 128]             784\n",
      "             ReLU-12         [64, 16, 128, 128]               0\n",
      "           Conv2d-13         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-14         [64, 16, 128, 128]              32\n",
      "           Conv2d-15         [64, 16, 128, 128]             784\n",
      "             ReLU-16         [64, 16, 128, 128]               0\n",
      "           Conv2d-17         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-18         [64, 16, 128, 128]              32\n",
      "             ReLU-19         [64, 16, 128, 128]               0\n",
      "           Conv2d-20         [64, 16, 128, 128]             784\n",
      "             ReLU-21         [64, 16, 128, 128]               0\n",
      "           Conv2d-22         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-23         [64, 16, 128, 128]              32\n",
      "        Dropout2d-24         [64, 16, 128, 128]               0\n",
      "        Dropout2d-25         [64, 16, 128, 128]               0\n",
      "    SS_nbt_module-26         [64, 32, 128, 128]               0\n",
      "           Conv2d-27         [64, 16, 128, 128]             784\n",
      "             ReLU-28         [64, 16, 128, 128]               0\n",
      "           Conv2d-29         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-30         [64, 16, 128, 128]              32\n",
      "             ReLU-31         [64, 16, 128, 128]               0\n",
      "           Conv2d-32         [64, 16, 128, 128]             784\n",
      "             ReLU-33         [64, 16, 128, 128]               0\n",
      "           Conv2d-34         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-35         [64, 16, 128, 128]              32\n",
      "           Conv2d-36         [64, 16, 128, 128]             784\n",
      "             ReLU-37         [64, 16, 128, 128]               0\n",
      "           Conv2d-38         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-39         [64, 16, 128, 128]              32\n",
      "             ReLU-40         [64, 16, 128, 128]               0\n",
      "           Conv2d-41         [64, 16, 128, 128]             784\n",
      "             ReLU-42         [64, 16, 128, 128]               0\n",
      "           Conv2d-43         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-44         [64, 16, 128, 128]              32\n",
      "        Dropout2d-45         [64, 16, 128, 128]               0\n",
      "        Dropout2d-46         [64, 16, 128, 128]               0\n",
      "    SS_nbt_module-47         [64, 32, 128, 128]               0\n",
      "           Conv2d-48         [64, 16, 128, 128]             784\n",
      "             ReLU-49         [64, 16, 128, 128]               0\n",
      "           Conv2d-50         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-51         [64, 16, 128, 128]              32\n",
      "             ReLU-52         [64, 16, 128, 128]               0\n",
      "           Conv2d-53         [64, 16, 128, 128]             784\n",
      "             ReLU-54         [64, 16, 128, 128]               0\n",
      "           Conv2d-55         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-56         [64, 16, 128, 128]              32\n",
      "           Conv2d-57         [64, 16, 128, 128]             784\n",
      "             ReLU-58         [64, 16, 128, 128]               0\n",
      "           Conv2d-59         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-60         [64, 16, 128, 128]              32\n",
      "             ReLU-61         [64, 16, 128, 128]               0\n",
      "           Conv2d-62         [64, 16, 128, 128]             784\n",
      "             ReLU-63         [64, 16, 128, 128]               0\n",
      "           Conv2d-64         [64, 16, 128, 128]             784\n",
      "      BatchNorm2d-65         [64, 16, 128, 128]              32\n",
      "        Dropout2d-66         [64, 16, 128, 128]               0\n",
      "        Dropout2d-67         [64, 16, 128, 128]               0\n",
      "    SS_nbt_module-68         [64, 32, 128, 128]               0\n",
      "        MaxPool2d-69           [64, 32, 64, 64]               0\n",
      "           Conv2d-70           [64, 32, 64, 64]           9,248\n",
      "      BatchNorm2d-71           [64, 64, 64, 64]             128\n",
      "             ReLU-72           [64, 64, 64, 64]               0\n",
      " DownsamplerBlock-73           [64, 64, 64, 64]               0\n",
      "           Conv2d-74           [64, 32, 64, 64]           3,104\n",
      "             ReLU-75           [64, 32, 64, 64]               0\n",
      "           Conv2d-76           [64, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-77           [64, 32, 64, 64]              64\n",
      "             ReLU-78           [64, 32, 64, 64]               0\n",
      "           Conv2d-79           [64, 32, 64, 64]           3,104\n",
      "             ReLU-80           [64, 32, 64, 64]               0\n",
      "           Conv2d-81           [64, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-82           [64, 32, 64, 64]              64\n",
      "           Conv2d-83           [64, 32, 64, 64]           3,104\n",
      "             ReLU-84           [64, 32, 64, 64]               0\n",
      "           Conv2d-85           [64, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-86           [64, 32, 64, 64]              64\n",
      "             ReLU-87           [64, 32, 64, 64]               0\n",
      "           Conv2d-88           [64, 32, 64, 64]           3,104\n",
      "             ReLU-89           [64, 32, 64, 64]               0\n",
      "           Conv2d-90           [64, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-91           [64, 32, 64, 64]              64\n",
      "        Dropout2d-92           [64, 32, 64, 64]               0\n",
      "        Dropout2d-93           [64, 32, 64, 64]               0\n",
      "    SS_nbt_module-94           [64, 64, 64, 64]               0\n",
      "           Conv2d-95           [64, 32, 64, 64]           3,104\n",
      "             ReLU-96           [64, 32, 64, 64]               0\n",
      "           Conv2d-97           [64, 32, 64, 64]           3,104\n",
      "      BatchNorm2d-98           [64, 32, 64, 64]              64\n",
      "             ReLU-99           [64, 32, 64, 64]               0\n",
      "          Conv2d-100           [64, 32, 64, 64]           3,104\n",
      "            ReLU-101           [64, 32, 64, 64]               0\n",
      "          Conv2d-102           [64, 32, 64, 64]           3,104\n",
      "     BatchNorm2d-103           [64, 32, 64, 64]              64\n",
      "          Conv2d-104           [64, 32, 64, 64]           3,104\n",
      "            ReLU-105           [64, 32, 64, 64]               0\n",
      "          Conv2d-106           [64, 32, 64, 64]           3,104\n",
      "     BatchNorm2d-107           [64, 32, 64, 64]              64\n",
      "            ReLU-108           [64, 32, 64, 64]               0\n",
      "          Conv2d-109           [64, 32, 64, 64]           3,104\n",
      "            ReLU-110           [64, 32, 64, 64]               0\n",
      "          Conv2d-111           [64, 32, 64, 64]           3,104\n",
      "     BatchNorm2d-112           [64, 32, 64, 64]              64\n",
      "       Dropout2d-113           [64, 32, 64, 64]               0\n",
      "       Dropout2d-114           [64, 32, 64, 64]               0\n",
      "   SS_nbt_module-115           [64, 64, 64, 64]               0\n",
      "       MaxPool2d-116           [64, 64, 32, 32]               0\n",
      "          Conv2d-117           [64, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-118          [64, 128, 32, 32]             256\n",
      "            ReLU-119          [64, 128, 32, 32]               0\n",
      "DownsamplerBlock-120          [64, 128, 32, 32]               0\n",
      "          Conv2d-121           [64, 64, 32, 32]          12,352\n",
      "            ReLU-122           [64, 64, 32, 32]               0\n",
      "          Conv2d-123           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-124           [64, 64, 32, 32]             128\n",
      "            ReLU-125           [64, 64, 32, 32]               0\n",
      "          Conv2d-126           [64, 64, 32, 32]          12,352\n",
      "            ReLU-127           [64, 64, 32, 32]               0\n",
      "          Conv2d-128           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-129           [64, 64, 32, 32]             128\n",
      "          Conv2d-130           [64, 64, 32, 32]          12,352\n",
      "            ReLU-131           [64, 64, 32, 32]               0\n",
      "          Conv2d-132           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-133           [64, 64, 32, 32]             128\n",
      "            ReLU-134           [64, 64, 32, 32]               0\n",
      "          Conv2d-135           [64, 64, 32, 32]          12,352\n",
      "            ReLU-136           [64, 64, 32, 32]               0\n",
      "          Conv2d-137           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-138           [64, 64, 32, 32]             128\n",
      "       Dropout2d-139           [64, 64, 32, 32]               0\n",
      "       Dropout2d-140           [64, 64, 32, 32]               0\n",
      "   SS_nbt_module-141          [64, 128, 32, 32]               0\n",
      "          Conv2d-142           [64, 64, 32, 32]          12,352\n",
      "            ReLU-143           [64, 64, 32, 32]               0\n",
      "          Conv2d-144           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-145           [64, 64, 32, 32]             128\n",
      "            ReLU-146           [64, 64, 32, 32]               0\n",
      "          Conv2d-147           [64, 64, 32, 32]          12,352\n",
      "            ReLU-148           [64, 64, 32, 32]               0\n",
      "          Conv2d-149           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-150           [64, 64, 32, 32]             128\n",
      "          Conv2d-151           [64, 64, 32, 32]          12,352\n",
      "            ReLU-152           [64, 64, 32, 32]               0\n",
      "          Conv2d-153           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-154           [64, 64, 32, 32]             128\n",
      "            ReLU-155           [64, 64, 32, 32]               0\n",
      "          Conv2d-156           [64, 64, 32, 32]          12,352\n",
      "            ReLU-157           [64, 64, 32, 32]               0\n",
      "          Conv2d-158           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-159           [64, 64, 32, 32]             128\n",
      "       Dropout2d-160           [64, 64, 32, 32]               0\n",
      "       Dropout2d-161           [64, 64, 32, 32]               0\n",
      "   SS_nbt_module-162          [64, 128, 32, 32]               0\n",
      "          Conv2d-163           [64, 64, 32, 32]          12,352\n",
      "            ReLU-164           [64, 64, 32, 32]               0\n",
      "          Conv2d-165           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-166           [64, 64, 32, 32]             128\n",
      "            ReLU-167           [64, 64, 32, 32]               0\n",
      "          Conv2d-168           [64, 64, 32, 32]          12,352\n",
      "            ReLU-169           [64, 64, 32, 32]               0\n",
      "          Conv2d-170           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-171           [64, 64, 32, 32]             128\n",
      "          Conv2d-172           [64, 64, 32, 32]          12,352\n",
      "            ReLU-173           [64, 64, 32, 32]               0\n",
      "          Conv2d-174           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-175           [64, 64, 32, 32]             128\n",
      "            ReLU-176           [64, 64, 32, 32]               0\n",
      "          Conv2d-177           [64, 64, 32, 32]          12,352\n",
      "            ReLU-178           [64, 64, 32, 32]               0\n",
      "          Conv2d-179           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-180           [64, 64, 32, 32]             128\n",
      "       Dropout2d-181           [64, 64, 32, 32]               0\n",
      "       Dropout2d-182           [64, 64, 32, 32]               0\n",
      "   SS_nbt_module-183          [64, 128, 32, 32]               0\n",
      "          Conv2d-184           [64, 64, 32, 32]          12,352\n",
      "            ReLU-185           [64, 64, 32, 32]               0\n",
      "          Conv2d-186           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-187           [64, 64, 32, 32]             128\n",
      "            ReLU-188           [64, 64, 32, 32]               0\n",
      "          Conv2d-189           [64, 64, 32, 32]          12,352\n",
      "            ReLU-190           [64, 64, 32, 32]               0\n",
      "          Conv2d-191           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-192           [64, 64, 32, 32]             128\n",
      "          Conv2d-193           [64, 64, 32, 32]          12,352\n",
      "            ReLU-194           [64, 64, 32, 32]               0\n",
      "          Conv2d-195           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-196           [64, 64, 32, 32]             128\n",
      "            ReLU-197           [64, 64, 32, 32]               0\n",
      "          Conv2d-198           [64, 64, 32, 32]          12,352\n",
      "            ReLU-199           [64, 64, 32, 32]               0\n",
      "          Conv2d-200           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-201           [64, 64, 32, 32]             128\n",
      "       Dropout2d-202           [64, 64, 32, 32]               0\n",
      "       Dropout2d-203           [64, 64, 32, 32]               0\n",
      "   SS_nbt_module-204          [64, 128, 32, 32]               0\n",
      "          Conv2d-205           [64, 64, 32, 32]          12,352\n",
      "            ReLU-206           [64, 64, 32, 32]               0\n",
      "          Conv2d-207           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-208           [64, 64, 32, 32]             128\n",
      "            ReLU-209           [64, 64, 32, 32]               0\n",
      "          Conv2d-210           [64, 64, 32, 32]          12,352\n",
      "            ReLU-211           [64, 64, 32, 32]               0\n",
      "          Conv2d-212           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-213           [64, 64, 32, 32]             128\n",
      "          Conv2d-214           [64, 64, 32, 32]          12,352\n",
      "            ReLU-215           [64, 64, 32, 32]               0\n",
      "          Conv2d-216           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-217           [64, 64, 32, 32]             128\n",
      "            ReLU-218           [64, 64, 32, 32]               0\n",
      "          Conv2d-219           [64, 64, 32, 32]          12,352\n",
      "            ReLU-220           [64, 64, 32, 32]               0\n",
      "          Conv2d-221           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-222           [64, 64, 32, 32]             128\n",
      "       Dropout2d-223           [64, 64, 32, 32]               0\n",
      "       Dropout2d-224           [64, 64, 32, 32]               0\n",
      "   SS_nbt_module-225          [64, 128, 32, 32]               0\n",
      "          Conv2d-226           [64, 64, 32, 32]          12,352\n",
      "            ReLU-227           [64, 64, 32, 32]               0\n",
      "          Conv2d-228           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-229           [64, 64, 32, 32]             128\n",
      "            ReLU-230           [64, 64, 32, 32]               0\n",
      "          Conv2d-231           [64, 64, 32, 32]          12,352\n",
      "            ReLU-232           [64, 64, 32, 32]               0\n",
      "          Conv2d-233           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-234           [64, 64, 32, 32]             128\n",
      "          Conv2d-235           [64, 64, 32, 32]          12,352\n",
      "            ReLU-236           [64, 64, 32, 32]               0\n",
      "          Conv2d-237           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-238           [64, 64, 32, 32]             128\n",
      "            ReLU-239           [64, 64, 32, 32]               0\n",
      "          Conv2d-240           [64, 64, 32, 32]          12,352\n",
      "            ReLU-241           [64, 64, 32, 32]               0\n",
      "          Conv2d-242           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-243           [64, 64, 32, 32]             128\n",
      "       Dropout2d-244           [64, 64, 32, 32]               0\n",
      "       Dropout2d-245           [64, 64, 32, 32]               0\n",
      "   SS_nbt_module-246          [64, 128, 32, 32]               0\n",
      "          Conv2d-247           [64, 64, 32, 32]          12,352\n",
      "            ReLU-248           [64, 64, 32, 32]               0\n",
      "          Conv2d-249           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-250           [64, 64, 32, 32]             128\n",
      "            ReLU-251           [64, 64, 32, 32]               0\n",
      "          Conv2d-252           [64, 64, 32, 32]          12,352\n",
      "            ReLU-253           [64, 64, 32, 32]               0\n",
      "          Conv2d-254           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-255           [64, 64, 32, 32]             128\n",
      "          Conv2d-256           [64, 64, 32, 32]          12,352\n",
      "            ReLU-257           [64, 64, 32, 32]               0\n",
      "          Conv2d-258           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-259           [64, 64, 32, 32]             128\n",
      "            ReLU-260           [64, 64, 32, 32]               0\n",
      "          Conv2d-261           [64, 64, 32, 32]          12,352\n",
      "            ReLU-262           [64, 64, 32, 32]               0\n",
      "          Conv2d-263           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-264           [64, 64, 32, 32]             128\n",
      "       Dropout2d-265           [64, 64, 32, 32]               0\n",
      "       Dropout2d-266           [64, 64, 32, 32]               0\n",
      "   SS_nbt_module-267          [64, 128, 32, 32]               0\n",
      "          Conv2d-268           [64, 64, 32, 32]          12,352\n",
      "            ReLU-269           [64, 64, 32, 32]               0\n",
      "          Conv2d-270           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-271           [64, 64, 32, 32]             128\n",
      "            ReLU-272           [64, 64, 32, 32]               0\n",
      "          Conv2d-273           [64, 64, 32, 32]          12,352\n",
      "            ReLU-274           [64, 64, 32, 32]               0\n",
      "          Conv2d-275           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-276           [64, 64, 32, 32]             128\n",
      "          Conv2d-277           [64, 64, 32, 32]          12,352\n",
      "            ReLU-278           [64, 64, 32, 32]               0\n",
      "          Conv2d-279           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-280           [64, 64, 32, 32]             128\n",
      "            ReLU-281           [64, 64, 32, 32]               0\n",
      "          Conv2d-282           [64, 64, 32, 32]          12,352\n",
      "            ReLU-283           [64, 64, 32, 32]               0\n",
      "          Conv2d-284           [64, 64, 32, 32]          12,352\n",
      "     BatchNorm2d-285           [64, 64, 32, 32]             128\n",
      "       Dropout2d-286           [64, 64, 32, 32]               0\n",
      "       Dropout2d-287           [64, 64, 32, 32]               0\n",
      "   SS_nbt_module-288          [64, 128, 32, 32]               0\n",
      "         Encoder-289          [64, 128, 32, 32]               0\n",
      "AdaptiveAvgPool2d-290            [64, 128, 1, 1]               0\n",
      "          Conv2d-291             [64, 11, 1, 1]           1,419\n",
      "     BatchNorm2d-292             [64, 11, 1, 1]              22\n",
      "            ReLU-293             [64, 11, 1, 1]               0\n",
      "    Conv2dBnRelu-294             [64, 11, 1, 1]               0\n",
      "          Conv2d-295           [64, 11, 32, 32]           1,419\n",
      "     BatchNorm2d-296           [64, 11, 32, 32]              22\n",
      "            ReLU-297           [64, 11, 32, 32]               0\n",
      "    Conv2dBnRelu-298           [64, 11, 32, 32]               0\n",
      "          Conv2d-299            [64, 1, 16, 16]           6,273\n",
      "     BatchNorm2d-300            [64, 1, 16, 16]               2\n",
      "            ReLU-301            [64, 1, 16, 16]               0\n",
      "    Conv2dBnRelu-302            [64, 1, 16, 16]               0\n",
      "          Conv2d-303              [64, 1, 8, 8]              26\n",
      "     BatchNorm2d-304              [64, 1, 8, 8]               2\n",
      "            ReLU-305              [64, 1, 8, 8]               0\n",
      "    Conv2dBnRelu-306              [64, 1, 8, 8]               0\n",
      "          Conv2d-307              [64, 1, 4, 4]              10\n",
      "     BatchNorm2d-308              [64, 1, 4, 4]               2\n",
      "            ReLU-309              [64, 1, 4, 4]               0\n",
      "    Conv2dBnRelu-310              [64, 1, 4, 4]               0\n",
      "          Conv2d-311              [64, 1, 4, 4]              10\n",
      "     BatchNorm2d-312              [64, 1, 4, 4]               2\n",
      "            ReLU-313              [64, 1, 4, 4]               0\n",
      "    Conv2dBnRelu-314              [64, 1, 4, 4]               0\n",
      "          Conv2d-315              [64, 1, 8, 8]              26\n",
      "     BatchNorm2d-316              [64, 1, 8, 8]               2\n",
      "            ReLU-317              [64, 1, 8, 8]               0\n",
      "    Conv2dBnRelu-318              [64, 1, 8, 8]               0\n",
      "          Conv2d-319            [64, 1, 16, 16]              50\n",
      "     BatchNorm2d-320            [64, 1, 16, 16]               2\n",
      "            ReLU-321            [64, 1, 16, 16]               0\n",
      "    Conv2dBnRelu-322            [64, 1, 16, 16]               0\n",
      "      APN_Module-323           [64, 11, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 920,725\n",
      "Trainable params: 920,725\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 48.00\n",
      "Forward/backward pass size (MB): 18780.90\n",
      "Params size (MB): 3.51\n",
      "Estimated Total Size (MB): 18832.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# training hyperparameters\n",
    "device = 'cpu'\n",
    "batch_size = 64\n",
    "n_epochs = 50\n",
    "\n",
    "# model, loss, score function\n",
    "model = lednet.LEDNet(num_classes=n_classes, output_size=(tH, tW))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "score_fn = metrics.batch_mIoU\n",
    "\n",
    "# optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# printing model summary\n",
    "torchsummary.summary(model=model, input_size=(3, tH, tW), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "results = training_and_testing.train_model(\n",
    "    device, model, test_dataset, batch_size, n_epochs, score_fn, loss_fn, optimizer, lr_scheduler=None, evaluate=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting training results\n",
    "training_and_testing.plot_training_results(results, plotsize=(20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting model, optimizer, learning rate scheduler\n",
    "final_model = lednet.LEDNet(num_classes=n_classes)\n",
    "final_optimizer = torch.optim.Adam(final_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# re-training model on entire training set and saving its weights\n",
    "final_n_epochs = 25\n",
    "training_and_testing.train_model(\n",
    "    device, final_model, train_dataset, batch_size, final_n_epochs, score_fn, loss_fn, final_optimizer, verbose=True)\n",
    "torch.save(final_model.state_dict(), weights_path + model_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained final model\n",
    "try:\n",
    "    final_model\n",
    "except:\n",
    "    final_model = lednet.LEDNet(num_classes=n_classes)\n",
    "    final_model.load_state_dict(torch.load(weights_path + model_name + '.pth'))\n",
    "\n",
    "# testing model on test dataset\n",
    "test_score_fn = metrics.batch_IoU\n",
    "label_names = list(segmentation_labels.labels.keys())\n",
    "batch_IoU = training_and_testing.test_model(device, final_model, test_dataset, batch_size, test_score_fn)\n",
    "batch_IoU_with_labels = { label: score for label, score in list(zip(label_names, batch_IoU.tolist())) }\n",
    "batch_mIoU = batch_IoU.mean().item()\n",
    "for label in batch_IoU_with_labels:\n",
    "    print(f'batch_IoU_{label}: {batch_IoU_with_labels[label]}')\n",
    "print(f'batch_mIoU={batch_mIoU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting some random examples from test dataset\n",
    "random_images = torch.zeros((n_examples, 3, tH, tW))\n",
    "random_targets = torch.zeros((n_examples, n_classes, tH, tW))\n",
    "for i in range(n_examples):\n",
    "    random_idx = torch.randint(high=len(test_dataset), size=(1,))\n",
    "    random_image, random_target = test_dataset[random_idx]\n",
    "    random_images[i] = random_image\n",
    "    random_targets[i] = random_target\n",
    "with torch.no_grad():\n",
    "    final_model.eval()\n",
    "    random_output = final_model(random_images)[0]\n",
    "channels_max, _ = torch.max(random_output, axis=1)\n",
    "random_predictions = (random_output == channels_max.unsqueeze(axis=1))\n",
    "for i in range(n_examples):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Ground Truth')\n",
    "    plt.imshow(utils.from_DHW_to_HWD(color_processing.colorize_segmentation_masks(random_targets[i], segmentation_labels.labels)))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Prediction')\n",
    "    plt.imshow(utils.from_DHW_to_HWD(color_processing.colorize_segmentation_masks(random_predictions[i], segmentation_labels.labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7035b1fba47350ac926f595c0cf89eb9aa595e837aeef931238e88411bd168d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
